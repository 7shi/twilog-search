# Twilogベクトル検索システム設計計画

## なぜこの実装が存在するか

### 意味的検索の必要性
**Problem**: 単純な単語マッチングでは「git」「コミット」「リポジトリ」などの関連語や、表現の多様性に対応できない。「ソースコード管理」「変更履歴」「バージョン管理システム」などの同義語も検索対象にならない。

**Solution**: テキストをベクトル化し、コサイン類似度による意味的検索を実装。表現が異なっても概念的に近い投稿を発見できる。

### データ規模と実装方式の選択
**Problem**: 22万件の投稿データに対して、複雑なベクトルDBやクラウドサービスを導入すると過剰な複雑性とコストが発生する。

**Solution**: 分割ファイル格納方式を採用。
- 1000件ごとの分割処理で安全性確保
- safetensors形式による高速読み込み
- 中断・再開機能による長時間処理への対応
- インメモリ検索により数ミリ秒での全件検索

### データ前処理の重要性
**Problem**: 投稿データにはURL、メンション、ハッシュタグなどのノイズが含まれ、意味的ベクトル化の精度を低下させる。

**Solution**: ベクトル化前にURL除去、空白正規化などの前処理を実装。意味のあるテキストのみを対象とする。

### タグ検出システムの設計
**Problem**: 22万件の投稿から手動でタグを抽出するのは現実的でなく、クラウドAPIの利用はコストと処理時間の課題を伴う。
**Solution**: ローカルLLMによる逐次処理と、Gemini APIによるバッチ処理を組み合わせたハイブリッドな自動タグ付けシステムを構築。これにより、コストと処理時間のバランスを取りながら、大規模データに対応する。

### ハイブリッド検索システムの必要性
**Problem**: 単純なベクトル検索では、直接的な類似度のみで判断するため、関連性の高い投稿を見逃す可能性がある。例えば「バージョン管理」で検索した際に、内容は異なるが「git」タグを持つ関連投稿が検索対象外になる。

**Solution**: ベクトル検索とタグ検索を組み合わせたハイブリッド検索を実装。
- 検索語と投稿内容の直接的なベクトル類似度検索
- 検索語と類似するタグを特定し、そのタグを持つ投稿も対象化
- 二つの検索結果を統合してランキング
- 網羅性と精度の両立を実現

### 検索結果統合の重要性
**Problem**: 直接類似度検索とタグ経由検索で異なるスコア体系を持つため、単純な結果マージでは適切なランキングができない。

**Solution**: スコア統合戦略を採用。
- 直接類似度: 重み0.7（内容の関連性を重視）
- タグ経由類似度: 重み0.3（関連トピックの発見性を重視）
- 重複投稿の除去と最終ランキング算出
- 検索意図に応じた重み調整が可能

### WebSocketベースのアーキテクチャ分離と統合
**Problem**: ベクトル検索機能をアプリケーションに統合すると、重いライブラリ（torch、SentenceTransformers）の読み込みにより、開発時の頻繁な再起動で生産性が低下する。また、MCPサーバー（TypeScript）とSearchEngine（Python）でフィルタリング機能が二重実装され、保守性とコードの一貫性に問題があった。

**Solution**: SearchEngine中心の統合アーキテクチャを採用。
- **twilog_server.py**: 統合検索サーバー（デーモン）
- **search.py**: 軽量フロントエンド
- **MCPサーバー**: 単純なWebSocketラッパー
- 機能の一元化による保守性向上と開発効率改善

## 自動タグ付けパイプライン

### 1. 比較検討: 逐次処理 vs バッチ処理
- **逐次処理 (`add_tags.py`)**: ローカルLLM（Ollama）を利用。小規模なテストやGPU環境下での実行には向くが、全データ（22万件）の処理に約158時間かかると試算され、スケーラビリティに課題。
- **バッチ処理（Gemini API）**: クラウドの並列処理能力を最大限に活用。全データ処理を約9時間で完了（17.6倍高速化）し、コストと時間の両面で圧倒的に優位であることが確認された。

### 2. バッチ処理パイプライン
Geminiバッチ処理を効率化するため、以下のツール群を開発・整備した。
- **リクエスト生成 (`batch_generate.py`)**: APIの仕様に合わせ、1万件ずつのJSONLリクエストファイルを生成する。
- **ジョブ管理 (`gemini-batch`)**: バッチジョブの投入、進捗監視、結果取得を自動化する独立CLIツール。
- **結果分析 (`batch_usage.py`)**: 処理結果のトークン使用量やコストを計算・検証し、データ品質を担保する。
- **結果統合 (`batch_merge.py`)**: 全バッチの結果ファイルをマージし、重複除去と整合性チェックを経て、単一のタグ付きデータセットを生成する。

### 3. ハイブリッド検索用データ生成
- **要旨ベクトル化 (`batch_vectorize.py`)**: 統合されたタグ情報（reasoning, summary）を個別にベクトル化し、内容の類似度だけでなく、LLMが生成した要約や理由に基づいた多角的な検索を可能にする。

### ローカルLLM可用性検証（予定）
Geminiバッチ処理は効率的だが、単一APIへの依存により選択肢が制限される。ローカルLLM（Ollama + Qwen3）の可用性を検証し、API依存のリスクを軽減する必要がある。
- **検証対象**: ローカルLLMによるタグ付け処理の実用性評価
- **評価指標**: 実用最低ラインの品質達成、処理安定性、依存関係の独立性
- **実装タイミング**: 統合システム完了後のオプション作業
- **比較項目**: 
  - 処理時間（Gemini: 9時間 vs ローカル: 158時間）
  - 品質（実用最低ライン達成の有無）
  - 可用性（API依存なし、完全ローカル処理）
  - コスト（API料金 vs 電力・時間コスト）
- **期待結果**: API依存リスクを軽減するローカル処理選択肢の確立
- **現状**: Geminiバッチ処理が効率性で圧倒的優位、可用性検証が残り課題

## ファイル構成
```
twilog/
├── twilog.csv                # 元データ（CSVベースアクセス）
├── embeddings/               # ベクトル検索用（分割ファイル）
│   ├── 0000.safetensors      # 投稿ベクトル（1000件ずつ）
│   ├── ...                   # ...
│   └── meta.json             # メタデータ（CSVパス含む）
├── tags/                     # タグ情報（分割ファイル、オプション）
│   ├── 0000.jsonl            # タグデータ（1000件ずつ）
│   └── ...
├── batch/                    # バッチAPIリクエスト（オプション）
│   ├── 001.jsonl             # Geminiバッチ用リクエスト（1万件ずつ）
│   ├── ...                   # ...
│   ├── results/              # Geminiバッチ処理結果（分割ファイル）
│   │   ├── 001.jsonl         # バッチ処理結果（1万件ずつ、reasoning/summary含む）
│   │   └── ...               # ...
│   ├── results.jsonl         # 統合されたバッチ処理結果（全件、batch_merge.py出力）
│   ├── tags.tsv              # タグデータ（TSV形式、tag_dump.py出力）
│   ├── tags.txt              # ユニークタグリスト（TXT形式、tag_vectorize.py出力）
│   └── tags.safetensors      # タグベクトル（safetensors形式、tag_vectorize.py出力）
├── src/                      # Pythonソースコード
│   ├── tag_*.py              # タグ分析ツール群（7段階パイプライン）
│   ├── batch_*.py            # バッチ処理ツール群（4段階パイプライン）
│   ├── search*.py            # 検索システム（統合サーバー＋軽量フロントエンド）
│   ├── embed_*.py            # ベクトル化基盤（サーバー＋クライアント）
│   └── *.py                  # その他ツール・ユーティリティ
└── mcp/src/index.ts          # MCPラッパー
```

## 実装状況

### 完了済み: コア機能とアーキテクチャ
- **データ処理パイプライン**:
  - **タグ付け**: Geminiバッチ処理による22万件のタグ付け（`batch_generate.py` -> `gemini-batch` -> `batch_merge.py`）
  - **ベクトル化**: `batch_vectorize.py`によるハイブリッド検索用データの生成
- **統合アーキテクチャ**:
  - `twilog_server.py`を中心としたデーモン構成
  - `search_engine.py`へのフィルタリング機能集約
  - `search.py`の軽量フロントエンド化
  - `mcp/src/index.ts`のWebSocketラッパー化によるSQLite実装の完全排除
- **ハイブリッド検索システム**:
  - 6種類の検索モード（content, reasoning, summary, average, maximum, minimum）
  - `SearchEngine`レベルでの重み付けスコア統合
  - 詳細は[ハイブリッド検索実装レポート](docs/20250715-hybrid-search.md)を参照
- **性能と保守性**:
  - 22万件データに対して数ミリ秒での高速検索
  - SearchEngineへの機能一元化によるコード重複の排除

### 完了済み: UI/UXと操作性向上
- **クライアント機能**:
  - **コマンドシステム**: `@command`デコレーターによる宣言的なコマンド登録と管理
  - **メニューUI**: `settings_ui.py`による統一的なメニューと数値ショートカット
  - **検索結果表示**: ページネーション機能、URL右寄せ、タグの色分け表示
  - **表示モード**: `/view`コマンドによる詳細表示機能
  - 詳細は[メニューUI設計レポート](docs/20250716-menu.md)を参照
- **ユーザー入力支援**:
  - **Tab補完**: `safe_input.py`によるユーザー名のTab補完
  - **類似ユーザー推薦**: Levenshtein距離を用いたタイポ訂正支援
- **情報管理**:
  - **UserInfoクラス**: `user_info.py`によるユーザー統計情報の一元管理
  - **MCP連携**: 検索モード対応とYAML形式での統一出力

### 完了済み: タグ分析基盤ツール群

#### タグ集計・分析システム（完了）
**Problem**: 22万件のタグ付けデータが完了したが、タグ自体の集計・分析機能がないため、タグの使用頻度や関連性を把握できない。

**Solution**: 依存順序に従った7段階のタグ分析パイプラインを実装。
- ✅ **タグデータ抽出**: `tag_dump.py`によるバッチ処理結果からTSV形式でのタグデータ抽出
- ✅ **タグベクトル化**: `tag_vectorize.py`による全タグの事前ベクトル化、safetensors形式保存、形状最適化（[N, 768]）
- ✅ **統合データアクセス**: `tag_reader.py`による分散データ（TSV、TXT、safetensors）の統合読み込み、遅延import対応
- ✅ **使用頻度分析**: `tag_analysis.py`による個別タグ使用頻度分析、対数スケールヒストグラム、順位別統計表示（TagReader統合）
- ✅ **共起関係分析**: `tag_cooc.py`によるタグ共起分析、関連性可視化、中心性分析（TagReader統合）
- ✅ **類似度分析**: `tag_similarity.py`によるタグ表記揺れ検出、コサイン類似度による定量的分析（TagReader統合）
- ✅ **共起率分析**: `tag_cooc_rate.py`による方向性を考慮した共起率分析、検索システム統合戦略検証、α=β=1重み付け妥当性確認

#### 完了済み: 検索システム統合戦略の設計検証
**Problem**: ベクトル類似度と共起率を統合した検索システムにおいて、適切な重み付け戦略（α=β=1）の妥当性を定量的に検証する必要があった。

**Solution**: 共起率分析により統合戦略を検証。
- ✅ **共起率分布分析**: 99.5%が0-4%の範囲に集中、自然に低重みとして機能することを確認
- ✅ **包含関係の定量化**: 「代数学」→「数学」97.8%など、専門用語から上位概念への階層的関連性を数値化
- ✅ **重み付け妥当性確認**: ベクトル類似度（0.8-0.95）と共起率（平均0.2%）の自然なバランスを実証
- ✅ **統合スコア設計**: α=β=1による単純加算の妥当性を統計的に確認

### 次世代タグベース検索システム（設計完了）

**Problem**: 従来のハイブリッド検索は投稿本文とクエリの類似度に依存していたが、タグが持つ豊富な意味的・文脈的関連性を十分に活用できていなかった。

**Solution**: タグの「類似度」と「共起率」を直接スコアとして利用する、より洗練されたタグベース検索アルゴリズムを設計。これにより、検索の精度と探索性を大幅に向上させる。

#### 1. コアタグ特定フェーズ

ユーザーの検索クエリから、検索の核となる「コアタグ」を特定する。**重要**: タグ類似度計算では全38,898タグとの類似度を必ず計算し、中間処理でのtop_k制限は一切行わない。

- **方式A: クエリのベクトル検索（推奨）**
  - **概要**: クエリをベクトル化し、`TagReader.calculate_all_tag_similarities()`で全タグとの類似度を計算する。
  - **長所**: 高速、低コスト。意味的に近いタグを直接発見でき、**全タグ情報により検索精度が劇的向上**。
  - **実装**: `search_similar_tags(top_k=N)`は使用禁止。必ず`calculate_all_tag_similarities()`を使用。
  - **根拠**: top_k制限により97%のタグ情報が失われ、検索精度が3-6倍悪化することが実証済み。

- **方式B: LLMによるクエリ解釈**
  - **概要**: クエリの意図をLLMに解釈させ、最も関連性の高いタグを生成させる。
  - **長所**: 自然言語の深い文脈理解が可能。複雑な要求にも対応できる。
  - **短所**: 高コスト、高レイテンシ。
  - **注意**: LLM出力もタグ類似度計算時は全タグとの比較が必要。

#### 2. 検索拡張とランキングフェーズ

特定されたコアタグを基点に、関連投稿を収集し、ランキングを行う。

- **ステップ1: タグ関連度スコアの計算**
  - 各投稿が持つタグとコアタグの関係性に基づき、投稿ごとに「タグ関連度スコア」を算出する。
  - **スコアリングルール**:
    - **類似タグ (同義語・類義語)**: コアタグと類似するタグを持つ投稿には、**ベクトル類似度**（例: 0.9以上）をスコアとする。
    - **共起タグ (文脈的関連語)**: コアタグと共起するタグを持つ投稿には、**共起率**（例: 0.1～0.4）をスコアとする。
  - **投稿レベルスコア統合**: 投稿が複数タグを持つ場合の統合手法（**検証結果に基づく推奨**）:
    - **mean手法（推奨）**: `np.mean(tag_similarities)` - 平均順位736.2で最優秀、実用的最適解
    - **q75手法（代替）**: `np.percentile(tag_similarities, 75)` - 外れ値耐性重視時に選択
    - **ハイブリッド手法は非推奨**: 投稿分類の困難性と保守性悪化により実用困難
  - **ポイント**: 類似度は共起率より自然に高い値を取るため、人為的な重み付けなしで「同義語 > 関連語」という優先順位が自動的に実現される。

- **ステップ2: 最終ランキング（多段階ソート）**
  - 「タグベース検索」の思想に基づき、以下の2段階でソートを実行する。
  - **第1キー**: **「タグ関連度スコア」**で降順ソート。
    - これにより、クエリとタグの関連性が最も高い投稿群が最上位に来る。
  - **第2キー**: **「本文類似度スコア」**（クエリと投稿本文の類似度）で降順ソート。
    - これは、第1キーのスコアが同点だった投稿グループ内での順位決定（タイブレーク）にのみ使用される。

#### 3. この設計の利点
- **思想の反映**: 「まずタグで絞り込み、次に内容で並べる」という検索意図を忠実に実現。
- **客観性とシンプルさ**: 人為的な係数を排し、データ（類似度・共起率）に基づいた客観的スコアリングと、堅牢な多段階ソートアルゴリズムを採用。
- **高い拡張性**: コアタグ特定方法を切り替えても、後段のランキング処理は共通して機能する。

#### 実装優先度と重要事項

1. **最高優先度**: **全タグ類似度計算の実装**
   - `TagReader.calculate_all_tag_similarities()`の必須使用
   - `search_similar_tags(top_k=N)`の使用完全禁止
   - **根拠**: top_k制限は検索精度を3-6倍悪化させる「早期最適化の罠」

2. **高優先度**: **直接的mean手法による投稿スコアリング**
   - summary→全タグ類似度計算→mean統合の既存手法を継続採用
   - 多段階ソート（タグスコア→本文類似度）の実装
   - **根拠**: core_tag_validation_3により直接手法の優位性が実証済み（平均順位736.2）

3. **中優先度**: 検索結果におけるタグ情報の表示改善（スコア内訳など）

4. ~~**非採用**: コアタグ特定方式（ベクトル検索 vs LLM）~~
   - **廃止理由**: LLMタグ抽出とRuri v3埋め込みの表現空間不一致により実用性が低い
   - **検証結果**: コアタグ手法（平均順位31,896.3） vs 直接手法（平均順位736.2）で43倍の性能差
   - **教訓**: 理論的魅力と実用性は必ずしも一致しない

5. **今後の課題**: 共起率分析は設計完了だが実装未検証のため、類似度ベースシステム完成後に検討

### **設計方針の重要な変更**

#### **コアタグベース検索の設計廃止**
**Problem**: 当初設計した「コアタグ特定→スコアリング」アプローチは理論的に優れているように見えたが、実証検証により実用性の低さが判明した。

**Solution**: 
- **採用継続**: 直接的なsummary→全タグ類似度計算によるmean手法
- **設計廃止**: 複雑なコアタグ経由のスコアリング手法
- **根拠**: LLM（Gemini）によるタグ抽出基準とベクトルモデル（Ruri v3）の表現空間が異なる方向性を持つため、中間変換段階が情報損失を招く

#### **シンプリシティの価値**
**教訓**: 複雑なアルゴリズムが必ずしも優れた結果をもたらすとは限らない。実用的検索システムでは：
1. **一貫性** > 特殊ケースでの部分最適化
2. **保守性** > 複雑な多段階処理
3. **実証性** > 理論的魅力

**結論**: 現行のmean手法ベースのハイブリッド検索システムが最適解として確定。
