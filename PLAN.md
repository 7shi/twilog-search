# Twilogベクトル検索システム設計計画

## なぜこの実装が存在するか

### 意味的検索の必要性
**Problem**: 単純な単語マッチングでは「git」「コミット」「リポジトリ」などの関連語や、表現の多様性に対応できない。「ソースコード管理」「変更履歴」「バージョン管理システム」などの同義語も検索対象にならない。

**Solution**: テキストをベクトル化し、コサイン類似度による意味的検索を実装。表現が異なっても概念的に近い投稿を発見できる。

### データ規模と実装方式の選択
**Problem**: 22万件の投稿データに対して、複雑なベクトルDBやクラウドサービスを導入すると過剰な複雑性とコストが発生する。

**Solution**: 分割ファイル格納方式を採用。
- 1000件ごとの分割処理で安全性確保
- safetensors形式による高速読み込み
- 中断・再開機能による長時間処理への対応
- インメモリ検索により数ミリ秒での全件検索

### SQLiteベクトル拡張の回避
**Problem**: sqlite-vssやsqlite-vecなどの拡張は導入が複雑で、依存関係が増える。また、SQLiteのBLOBでは直接的なコサイン類似度検索が困難。

**Solution**: safetensors形式での別ファイル保存を採用。
- 高速なメモリマップによる瞬時ロード
- 型安全性とバイナリ効率性
- 依存関係の最小化（safetensors + numpy）

### データ前処理の重要性
**Problem**: 投稿データにはURL、メンション、ハッシュタグなどのノイズが含まれ、意味的ベクトル化の精度を低下させる。

**Solution**: ベクトル化前にURL除去、空白正規化などの前処理を実装。意味のあるテキストのみを対象とする。

### タグ検出システムの設計
**Problem**: 22万件の投稿から手動でタグを抽出するのは現実的でない。また、クラウドAPIでは大量データの処理コストが高い。

**Solution**: 複数の処理方式による自動タグ付けシステム。

#### リアルタイム処理（add_tags.py）
- ローカルLLM（Ollama + Qwen3:4b）による逐次処理
- GPU環境での効率的なシーケンシャル処理
- チェックポイント機能による中断・再開対応
- Pydanticスキーマによる構造化出力
- 分割JSONL保存による効率的な管理
- 1件ずつ追記保存による処理安全性
- 処理時間: 約158時間（22万件）

#### バッチAPI処理（Gemini特化版）

##### 1. バッチリクエスト生成
**batch_generate.py**: Geminiバッチ処理API用のJSONLリクエスト生成
- 1万件ずつの最適チャンク分割（バッチAPI上限対応）
- add_tags.pyのプロンプトとスキーマ設計を継承
- リアルタイム処理の158時間から大幅な処理時間短縮を実現
- データ準備時間: 数分（JSONLリクエスト生成のみ）
- **実績**: 22.5万件を23バッチで処理、総処理時間約9時間（158時間→9時間の17.6倍高速化）

##### 2. バッチジョブ管理
**gemini-batch**: 独立バッチジョブ管理ツール（分離済み）
- リポジトリ: [gemini-batch](https://github.com/7shi/gemini-batch)
- 汎用的なGeminiバッチジョブ管理CLIツール
- `gembatch submit` / `gembatch poll` サブコマンド形式
- 複数ファイル一括投入・TUIベース進捗表示
- 自動リソースクリーンアップ機能
- インストール: `uv tool install https://github.com/7shi/gemini-batch.git`

##### 3. バッチ結果の分析と統合
**batch_usage.py**: バッチ処理結果の使用統計とコスト計算
- 各バッチファイルの処理数とトークン使用量を集計
- コスト計算と処理効率の可視化
- candidates構造の厚密な検証機能
- データ品質と完全性の確認
- **実績**: 総トークン使用量7,046万トークン、構造適合率100%

**batch_merge.py**: 複数バッチ結果ファイルの統合マージ
- batch/results/ディレクトリの全JSONLファイルを統合
- 重複除去とデータ整合性チェック
- 統一されたタグ付きデータの生成（batch/results.jsonl）
- 結果品質の検証とレポート生成
- **実績**: 22.5万件→22.5万件の完全統合（スキップ9件：ブロック2件、LLM暴走7件）

##### 4. タグベクトル化
**batch_vectorize.py**: JSONLファイルのreasoningとsummaryフィールド別ベクトル化
- vectorize.pyの汎用化された関数を再利用
- reasoning（理由）とsummary（要約）を個別にベクトル化
- タグベースのハイブリッド検索用データ生成
- batch/{reasoning,summary}/ディレクトリへの分割保存

### WebSocketベースのアーキテクチャ分離と統合
**Problem**: ベクトル検索機能をアプリケーションに統合すると、重いライブラリ（torch、SentenceTransformers）の読み込みにより、開発時の頻繁な再起動で生産性が低下する。また、MCPサーバー（TypeScript）とSearchEngine（Python）でフィルタリング機能が二重実装され、保守性とコードの一貫性に問題があった。

**Solution**: SearchEngine中心の統合アーキテクチャを採用。
- **twilog_server.py**: 統合検索サーバー（デーモン）
  - Ruri v3モデル初期化とembeddingsデータ読み込み
  - SearchEngineインスタンスによるフィルタリング統合
  - MCP互換メソッド（search_similar, get_user_stats等）提供
  - meta.jsonからCSVパス自動取得
- **search.py**: 軽量フロントエンド
  - twilog_server.pyのsearch_similarメソッド使用
  - UI処理と結果表示のみに特化
  - SearchEngineのインポートを削除、数秒での高速起動
- **MCPサーバー**: 単純なWebSocketラッパー
  - twilog_server.pyの各メソッドを直接転送
  - SQLiteベース実装（database.ts, filters.ts）を完全削除
  - フィルタリング処理の重複削除、コード簡素化
- 機能の一元化による保守性向上と開発効率改善

### ハイブリッド検索システムの必要性
**Problem**: 単純なベクトル検索では、直接的な類似度のみで判断するため、関連性の高い投稿を見逃す可能性がある。例えば「バージョン管理」で検索した際に、内容は異なるが「git」タグを持つ関連投稿が検索対象外になる。

**Solution**: ベクトル検索とタグ検索を組み合わせたハイブリッド検索を実装。
- 検索語と投稿内容の直接的なベクトル類似度検索
- 検索語と類似するタグを特定し、そのタグを持つ投稿も対象化
- 二つの検索結果を統合してランキング
- 網羅性と精度の両立を実現

### 検索結果統合の重要性
**Problem**: 直接類似度検索とタグ経由検索で異なるスコア体系を持つため、単純な結果マージでは適切なランキングができない。

**Solution**: スコア統合戦略を採用。
- 直接類似度: 重み0.7（内容の関連性を重視）
- タグ経由類似度: 重み0.3（関連トピックの発見性を重視）
- 重複投稿の除去と最終ランキング算出
- 検索意図に応じた重み調整が可能

## 技術選択の根拠

### 日本語embedding model
**採用技術**: Ruri v3（cl-nagoya/ruri-v3-310m）
- 日本語特化の310Mパラメータモデル
- 「検索文書: 」プレフィックスによる最適化
- 1024次元のベクトル表現
- GPU環境での高速処理

### ファイル構成
```
twilog/
├── twilog.csv                # 元データ（CSVベースアクセス）
├── embeddings/               # ベクトル検索用（分割ファイル）
│   ├── 0000.safetensors     # 投稿ベクトル（1000件ずつ）
│   ├── 0001.safetensors     # ...
│   ├── meta.json            # メタデータ（CSVパス含む）
│   └── ...
├── tags/                     # タグ情報（分割ファイル、オプション）
│   ├── 0000.jsonl           # タグデータ（1000件ずつ）
│   └── ...
├── batch/                    # バッチAPIリクエスト（オプション）
│   ├── 001.jsonl            # Geminiバッチ用リクエスト（1万件ずつ）
│   └── ...
├── embed_server.py           # 基底クラス（BaseEmbedServer）
├── twilog_server.py          # 統合WebSocketサーバー（SearchEngine統合）
├── twilog_client.py          # テスト用クライアント
├── search.py                 # 軽量検索クライアント（フロントエンド化）
├── search_engine.py          # フィルタリング機能の中核
├── data_csv.py               # CSVベースデータアクセス層
├── add_tags.py               # CSVベースタグ付けスクリプト（完了）
├── batch_generate.py         # バッチAPIリクエスト生成（完了）
└── gemini-batch/             # 独立バッチツール（分離済み）
└── mcp/src/index.ts          # MCPラッパー（SQLite実装削除済み）
```

## 実装状況

### 完了済み: 統合アーキテクチャシステム
- **embed_server.py**: 基底クラス（BaseEmbedServer）
  - 共通のデーモン管理とWebSocket通信
  - 拡張可能なリクエスト処理システム
  - エラーハンドリングと進捗報告
  - サーバー種別の動的識別機能
- **twilog_server.py**: 統合WebSocketサーバー（デーモン）
  - Ruri v3モデルによるベクトル検索
  - SearchEngineインスタンス統合によるフィルタリング
  - MCP互換メソッド（search_similar, get_user_stats等）
  - meta.jsonからCSVパス自動取得
  - 分割送信による大量結果の効率的転送
- **search_engine.py**: フィルタリング機能の中核
  - ユーザーフィルタリング、日付フィルタリング
  - 重複除去とランキング処理
  - CSV直接アクセスによるデータ取得
- **search.py**: 軽量検索クライアント（フロントエンド化）
  - twilog_server.pyのsearch_similarメソッド使用
  - UI処理と結果表示のみに特化
  - 数秒での高速起動（軽量化）
- **mcp/src/index.ts**: MCPラッパー
  - twilog_server.pyの各メソッドを直接転送
  - SQLiteベース実装削除によるシンプル化
  - database.ts/filters.ts削除済み
- **add_tags.py**: CSVベースタグ付けスクリプト
  - data_csv.pyによるCSVファイル直接読み込み
  - strip_content関数による前処理統合
  - SQLiteデータベース構築不要
- **batch_generate.py**: バッチAPIリクエスト生成
  - add_tags.pyのアーキテクチャとプロンプト設計を継承
  - GeminiバッチAPI用のJSONL形式出力
  - 1万件ずつの最適チャンク分割（バッチAPI上限対応）
  - 処理時間を158時間から数分（+API処理時間）に短縮
- **batch_usage.py**: バッチ処理結果の分析ツール
  - 使用統計とコスト計算機能
  - candidates構造の厚密な検証
  - データ品質と完全性の確認
- **batch_merge.py**: バッチ結果マージツール
  - 複数JSONLファイルの統合マージ
  - 重複除去とデータ整合性チェック
  - 結果品質の検証とレポート生成
- **batch_vectorize.py**: タグベクトル化ツール
  - JSONLファイルのreasoningとsummaryフィールド別ベクトル化
  - vectorize.pyの汎用化関数を再利用
  - ハイブリッド検索用データ生成
- **gemini-batchツール**: 独立バッチジョブ管理（分離済み）
  - リポジトリ: [gemini-batch](https://github.com/7shi/gemini-batch)
  - 汎用的なGeminiバッチジョブ管理CLIツール
  - TUIベースのリアルタイム進捗表示
  - 自動リソースクリーンアップ機能
- **タグ付けデータ**: Geminiバッチ処理により22万件のタグ付け完了
  - batch_generate.py → gemini-batch → batch_merge.py → batch_vectorize.py パイプライン実行済み
  - batch/results.jsonlとbatch/{reasoning,summary}/ディレクトリにデータ保存済み
  - ハイブリッド検索用データ準備完了（検索機能統合は未実装）
- **性能**: 22万件に対して数ミリ秒での高速検索
- **保守性**: SearchEngine中心の一元化による重複削除
- **開発効率**: CSVベースによる単純化とセットアップ時間短縮

### 次期実装予定: ハイブリッド検索システム

#### ハイブリッド検索の設計理念
**Problem**: 現在のベクトル検索では投稿内容のみの類似度に依存し、タグ付けの理由や要約の情報を活用できていない。また、用途に応じた検索モードの選択ができず、一律の検索結果しか得られない。

**Solution**: 3つのベクトル空間（投稿内容、タグ付け理由、要約）を統合した多層検索システムを実装。用途に応じて6種類の検索モードを選択可能とする。

#### 6種類の検索モード

##### 1. 単一ソース検索（3種類）
- **Content-Only**: 投稿内容のみとの類似度検索
- **Reasoning-Only**: タグ付け理由のみとの類似度検索
- **Summary-Only**: 要約のみとの類似度検索

##### 2. 統合検索（3種類）
- **Average**: 3つの類似度の平均値で統合
- **Product**: 3つの類似度の積で統合（相乗効果）
- **Weighted**: 重み付け平均で統合（5つのプリセット + カスタム設定）

#### 重み付け検索の詳細設計

##### 重み付けプリセット（5種類）
```
1. 内容重視 (0.7, 0.2, 0.1) - 投稿内容を重視
2. 理由重視 (0.2, 0.7, 0.1) - タグ付け理由を重視
3. 要約重視 (0.1, 0.2, 0.7) - 要約を重視
4. バランス (0.5, 0.3, 0.2) - 内容やや重視のバランス
5. 均等 (0.33, 0.33, 0.34) - 3要素を均等評価
```

##### カスタム重み設定
- ユーザーが任意の重み（合計1.0）を設定可能
- 入力検証機能による不正値の防止
- 設定値のリアルタイム調整機能

#### 基本検索フロー（実装予定）
1. **検索語のベクトル化**: twilog_server.pyでRuri v3によるベクトル化
2. **並列ベクトル検索実行**:
   - A. embeddings/（投稿内容）とのコサイン類似度検索
   - B. batch/reasoning/（タグ付け理由）とのコサイン類似度検索
   - C. batch/summary/（要約）とのコサイン類似度検索
3. **モード別スコア統合**: 選択されたモードに応じたスコア計算
4. **結果ランキング**: 重複除去と最終スコア順でソート

#### データ構造の活用
- **投稿内容ベクトル**: embeddings/ディレクトリ（既存）
- **タグ理由ベクトル**: batch/reasoning/ディレクトリ（batch_vectorize.py完了済み）
- **要約ベクトル**: batch/summary/ディレクトリ（batch_vectorize.py完了済み）

#### 後続実装予定: タグベース検索
ハイブリッド検索完成後、タグ自体の集計・分析を実施し、タグベースの検索機能を追加予定。
- **タグ集計**: 使用頻度、関連性分析
- **タグ検索**: 類似タグ発見とタグ経由投稿検索
- **統合検索**: ベクトル検索 + タグ検索の最終統合

この設計により、投稿内容・タグ付け理由・要約の3つの観点から柔軟で高精度な検索が可能になる。SearchEngine中心の統合アーキテクチャにより、CLI・MCP両方に統一的に反映される。

### ローカルLLM可用性検証（オプション実装予定）

#### Gemini vs ローカルLLMの可用性検証
**Problem**: Geminiバッチ処理は効率的だが、単一APIへの依存により選択肢が制限される。ローカルLLM（Ollama + Qwen3）の可用性を検証し、API依存のリスクを軽減する必要がある。

**Solution**: ハイブリッド検索システム完成後、可用性検証を実施。
- **検証対象**: ローカルLLMによるタグ付け処理の実用性評価
- **評価指標**: 実用最低ラインの品質達成、処理安定性、依存関係の独立性
- **実装タイミング**: 統合システム完了後のオプション作業
- **比較項目**: 
  - 処理時間（Gemini: 9時間 vs ローカル: 158時間）
  - 品質（実用最低ライン達成の有無）
  - 可用性（API依存なし、完全ローカル処理）
  - コスト（API料金 vs 電力・時間コスト）
- **期待結果**: API依存リスクを軽減するローカル処理選択肢の確立
- **現状**: Geminiバッチ処理が効率性で圧倒的優位、可用性検証が残り課題

### ユーザー入力補完システム（将来実装予定）

#### readline Tab補完機能
**Problem**: ユーザー名の入力時に正確な名前を覚えていない場合や、タイポが発生しやすい場合に、入力効率が低下している。既存のsafe_input.pyは汎用的な入力管理のため、特定用途の補完機能は分離して実装する必要がある。

**Solution**: safe_input.pyを拡張し、ユーザー名補完モードのON/OFF切り替え機能を実装予定。
- **補完モード管理**: ユーザー名補完の有効/無効を動的に切り替え
- **コンテキスト分離**: 通常入力と補完付き入力で異なる履歴管理
- **Tab補完機能**: 部分入力に対する前方一致ユーザー候補表示
- **統合設計**: 既存のHistoryManagerと連携し、補完機能使用時のみ有効化

#### 二段階ユーザー支援システム
**完了済み**: レーベンシュタイン距離による類似ユーザー検索（SearchEngine.suggest_similar_users）
**将来実装**: readline Tab補完との組み合わせによる包括的ユーザー支援
- **入力中**: Tab補完でリアルタイム候補表示
- **入力後**: 存在しないユーザーに対して類似ユーザー自動提案
- **使い分け**: 明確に知っている場合はTab補完、曖昧な場合は類似検索
