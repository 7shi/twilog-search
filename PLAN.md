# Twilogベクトル検索システム設計計画

## なぜこの実装が存在するか

### 意味的検索の必要性
**Problem**: 単純な単語マッチングでは「git」「コミット」「リポジトリ」などの関連語や、表現の多様性に対応できない。「ソースコード管理」「変更履歴」「バージョン管理システム」などの同義語も検索対象にならない。

**Solution**: テキストをベクトル化し、コサイン類似度による意味的検索を実装。表現が異なっても概念的に近い投稿を発見できる。

### データ規模と実装方式の選択
**Problem**: 22万件の投稿データに対して、複雑なベクトルDBやクラウドサービスを導入すると過剰な複雑性とコストが発生する。

**Solution**: 分割ファイル格納方式を採用。
- 1000件ごとの分割処理で安全性確保
- safetensors形式による高速読み込み
- 中断・再開機能による長時間処理への対応
- インメモリ検索により数ミリ秒での全件検索

### SQLiteベクトル拡張の回避
**Problem**: sqlite-vssやsqlite-vecなどの拡張は導入が複雑で、依存関係が増える。また、SQLiteのBLOBでは直接的なコサイン類似度検索が困難。

**Solution**: safetensors形式での別ファイル保存を採用。
- 高速なメモリマップによる瞬時ロード
- 型安全性とバイナリ効率性
- 依存関係の最小化（safetensors + numpy）

### データ前処理の重要性
**Problem**: 投稿データにはURL、メンション、ハッシュタグなどのノイズが含まれ、意味的ベクトル化の精度を低下させる。

**Solution**: ベクトル化前にURL除去、空白正規化などの前処理を実装。意味のあるテキストのみを対象とする。

### タグ検出システムの設計
**Problem**: 22万件の投稿から手動でタグを抽出するのは現実的でない。また、クラウドAPIでは大量データの処理コストが高い。

**Solution**: 複数の処理方式による自動タグ付けシステム。

#### リアルタイム処理（add_tags.py）
- ローカルLLM（Ollama + Qwen3:4b）による逐次処理
- GPU環境での効率的なシーケンシャル処理
- チェックポイント機能による中断・再開対応
- Pydanticスキーマによる構造化出力
- 分割JSONL保存による効率的な管理
- 1件ずつ追記保存による処理安全性
- 処理時間: 約158時間（22万件）

#### バッチAPI処理（Gemini特化版）

##### 1. バッチリクエスト生成
**batch_generate.py**: Geminiバッチ処理API用のJSONLリクエスト生成
- 1万件ずつの最適チャンク分割（バッチAPI上限対応）
- add_tags.pyのプロンプトとスキーマ設計を継承
- リアルタイム処理の158時間から大幅な処理時間短縮を実現
- データ準備時間: 数分（JSONLリクエスト生成のみ）
- **実績**: 22.5万件を23バッチで処理、総処理時間約9時間（158時間→9時間の17.6倍高速化）

##### 2. バッチジョブ管理
**gemini-batch**: 独立バッチジョブ管理ツール（分離済み）
- リポジトリ: [gemini-batch](https://github.com/7shi/gemini-batch)
- 汎用的なGeminiバッチジョブ管理CLIツール
- `gembatch submit` / `gembatch poll` サブコマンド形式
- 複数ファイル一括投入・TUIベース進捗表示
- 自動リソースクリーンアップ機能
- インストール: `uv tool install https://github.com/7shi/gemini-batch.git`

##### 3. バッチ結果の分析と統合
**batch_usage.py**: バッチ処理結果の使用統計とコスト計算
- 各バッチファイルの処理数とトークン使用量を集計
- コスト計算と処理効率の可視化
- candidates構造の厚密な検証機能
- データ品質と完全性の確認
- **実績**: 総トークン使用量7,046万トークン、構造適合率100%

**batch_merge.py**: 複数バッチ結果ファイルの統合マージ
- batch/results/ディレクトリの全JSONLファイルを統合
- 重複除去とデータ整合性チェック
- 統一されたタグ付きデータの生成
- 結果品質の検証とレポート生成
- **実績**: 22.5万件→22.5万件の完全統合（スキップ9件：ブロック2件、LLM暴走7件）

##### 4. タグベクトル化
**batch_vectorize.py**: JSONLファイルのreasoningとsummaryフィールド別ベクトル化
- vectorize.pyの汎用化された関数を再利用
- reasoning（理由）とsummary（要約）を個別にベクトル化
- タグベースのハイブリッド検索用データ生成
- embeddings_tags/ディレクトリへの分割保存

### WebSocketベースのアーキテクチャ分離と統合
**Problem**: ベクトル検索機能をアプリケーションに統合すると、重いライブラリ（torch、SentenceTransformers）の読み込みにより、開発時の頻繁な再起動で生産性が低下する。また、MCPサーバー（TypeScript）とSearchEngine（Python）でフィルタリング機能が二重実装され、保守性とコードの一貫性に問題があった。

**Solution**: SearchEngine中心の統合アーキテクチャを採用。
- **twilog_server.py**: 統合検索サーバー（デーモン）
  - Ruri v3モデル初期化とembeddingsデータ読み込み
  - SearchEngineインスタンスによるフィルタリング統合
  - MCP互換メソッド（search_similar, get_user_stats等）提供
  - meta.jsonからCSVパス自動取得
- **search.py**: 軽量フロントエンド
  - twilog_server.pyのsearch_similarメソッド使用
  - UI処理と結果表示のみに特化
  - SearchEngineのインポートを削除、数秒での高速起動
- **MCPサーバー**: 単純なWebSocketラッパー
  - twilog_server.pyの各メソッドを直接転送
  - SQLiteベース実装（database.ts, filters.ts）を完全削除
  - フィルタリング処理の重複削除、コード簡素化
- 機能の一元化による保守性向上と開発効率改善

### ハイブリッド検索システムの必要性
**Problem**: 単純なベクトル検索では、直接的な類似度のみで判断するため、関連性の高い投稿を見逃す可能性がある。例えば「バージョン管理」で検索した際に、内容は異なるが「git」タグを持つ関連投稿が検索対象外になる。

**Solution**: ベクトル検索とタグ検索を組み合わせたハイブリッド検索を実装。
- 検索語と投稿内容の直接的なベクトル類似度検索
- 検索語と類似するタグを特定し、そのタグを持つ投稿も対象化
- 二つの検索結果を統合してランキング
- 網羅性と精度の両立を実現

### 検索結果統合の重要性
**Problem**: 直接類似度検索とタグ経由検索で異なるスコア体系を持つため、単純な結果マージでは適切なランキングができない。

**Solution**: スコア統合戦略を採用。
- 直接類似度: 重み0.7（内容の関連性を重視）
- タグ経由類似度: 重み0.3（関連トピックの発見性を重視）
- 重複投稿の除去と最終ランキング算出
- 検索意図に応じた重み調整が可能

## 技術選択の根拠

### 日本語embedding model
**採用技術**: Ruri v3（cl-nagoya/ruri-v3-310m）
- 日本語特化の310Mパラメータモデル
- 「検索文書: 」プレフィックスによる最適化
- 1024次元のベクトル表現
- GPU環境での高速処理

### ファイル構成
```
twilog/
├── twilog.csv                # 元データ（CSVベースアクセス）
├── embeddings/               # ベクトル検索用（分割ファイル）
│   ├── 0000.safetensors     # 投稿ベクトル（1000件ずつ）
│   ├── 0001.safetensors     # ...
│   ├── meta.json            # メタデータ（CSVパス含む）
│   └── ...
├── tags/                     # タグ情報（分割ファイル、オプション）
│   ├── 0000.jsonl           # タグデータ（1000件ずつ）
│   └── ...
├── batch/                    # バッチAPIリクエスト（オプション）
│   ├── 001.jsonl            # Geminiバッチ用リクエスト（1万件ずつ）
│   └── ...
├── embed_server.py           # 基底クラス（BaseEmbedServer）
├── twilog_server.py          # 統合WebSocketサーバー（SearchEngine統合）
├── twilog_client.py          # テスト用クライアント
├── search.py                 # 軽量検索クライアント（フロントエンド化）
├── search_engine.py          # フィルタリング機能の中核
├── data_csv.py               # CSVベースデータアクセス層
├── add_tags.py               # CSVベースタグ付けスクリプト（完了）
├── batch_generate.py         # バッチAPIリクエスト生成（完了）
└── gemini-batch/             # 独立バッチツール（分離済み）
└── mcp/src/index.ts          # MCPラッパー（SQLite実装削除済み）
```

## 実装状況

### 完了済み: 統合アーキテクチャシステム
- **embed_server.py**: 基底クラス（BaseEmbedServer）
  - 共通のデーモン管理とWebSocket通信
  - 拡張可能なリクエスト処理システム
  - エラーハンドリングと進捗報告
  - サーバー種別の動的識別機能
- **twilog_server.py**: 統合WebSocketサーバー（デーモン）
  - Ruri v3モデルによるベクトル検索
  - SearchEngineインスタンス統合によるフィルタリング
  - MCP互換メソッド（search_similar, get_user_stats等）
  - meta.jsonからCSVパス自動取得
  - 分割送信による大量結果の効率的転送
- **search_engine.py**: フィルタリング機能の中核
  - ユーザーフィルタリング、日付フィルタリング
  - 重複除去とランキング処理
  - CSV直接アクセスによるデータ取得
- **search.py**: 軽量検索クライアント（フロントエンド化）
  - twilog_server.pyのsearch_similarメソッド使用
  - UI処理と結果表示のみに特化
  - 数秒での高速起動（軽量化）
- **mcp/src/index.ts**: MCPラッパー
  - twilog_server.pyの各メソッドを直接転送
  - SQLiteベース実装削除によるシンプル化
  - database.ts/filters.ts削除済み
- **add_tags.py**: CSVベースタグ付けスクリプト
  - data_csv.pyによるCSVファイル直接読み込み
  - strip_content関数による前処理統合
  - SQLiteデータベース構築不要
- **batch_generate.py**: バッチAPIリクエスト生成
  - add_tags.pyのアーキテクチャとプロンプト設計を継承
  - GeminiバッチAPI用のJSONL形式出力
  - 1万件ずつの最適チャンク分割（バッチAPI上限対応）
  - 処理時間を158時間から数分（+API処理時間）に短縮
- **batch_usage.py**: バッチ処理結果の分析ツール
  - 使用統計とコスト計算機能
  - candidates構造の厚密な検証
  - データ品質と完全性の確認
- **batch_merge.py**: バッチ結果マージツール
  - 複数JSONLファイルの統合マージ
  - 重複除去とデータ整合性チェック
  - 結果品質の検証とレポート生成
- **batch_vectorize.py**: タグベクトル化ツール
  - JSONLファイルのreasoningとsummaryフィールド別ベクトル化
  - vectorize.pyの汎用化関数を再利用
  - ハイブリッド検索用データ生成
- **gemini-batchツール**: 独立バッチジョブ管理（分離済み）
  - リポジトリ: [gemini-batch](https://github.com/7shi/gemini-batch)
  - 汎用的なGeminiバッチジョブ管理CLIツール
  - TUIベースのリアルタイム進捗表示
  - 自動リソースクリーンアップ機能
- **タグ付けデータ**: Geminiバッチ処理により22万件のタグ付け完了
  - batch_generate.py → gemini-batch → batch_merge.py → batch_vectorize.py パイプライン実行済み
  - tags_merged/とembeddings_tags/ディレクトリにデータ保存済み
  - ハイブリッド検索用データ準備完了（検索機能統合は未実装）
- **性能**: 22万件に対して数ミリ秒での高速検索
- **保守性**: SearchEngine中心の一元化による重複削除
- **開発効率**: CSVベースによる単純化とセットアップ時間短縮

### 次期実装予定: ハイブリッド検索システム

#### 基本検索フロー（タグ付けデータ準備済み）
1. **検索語のベクトル化**: twilog_server.pyでRuri v3によるベクトル化
2. **並列検索実行**:
   - A. twilog_server.py内でembeddings/とのコサイン類似度検索
   - B. search.py内でtags/内のJSONLファイルからのタグ検索
3. **タグ経由投稿の取得**: 類似タグに紐づく投稿をJSONLから取得
4. **スコア統合**: 直接類似度とタグ経由類似度を重み付け統合
5. **結果ランキング**: 重複除去と最終スコア順でソート

#### タグ検索の実装案（要検証）

**案1: ベクトルベース類似タグ検索**
- **アプローチ**: クエリ→タグベクトル類似度→該当投稿選択
- **実装手順**:
  1. 抽出済みタグ一覧をRuri v3でベクトル化（事前処理）
  2. 検索クエリとタグベクトル間のコサイン類似度計算
  3. 閾値以上の類似度を持つタグを特定
  4. 該当タグを含む投稿を検索結果に追加
- **利点**: 既存のRuri v3モデル活用、実装シンプル
- **課題**: タグベクトル化の事前処理が必要

**案2: LLMベースタグ生成検索**
- **アプローチ**: クエリ→LLMタグ生成→タグマッチング→投稿選択
- **実装手順**:
  1. 検索クエリをOllama + Qwen3に投げてタグ生成
  2. 生成タグと既存タグの完全一致・部分一致
  3. マッチしたタグを持つ投稿を特定
  4. 該当投稿を検索結果に統合
- **利点**: 柔軟で意味的な関連性発見が可能
- **課題**: LLM呼び出しレイテンシ、生成タグ品質の不確実性

この設計により、高精度な意味的検索と網羅的な関連投稿発見を22万件規模で実現予定。SearchEngine中心の統合アーキテクチャにより、タグ検索機能の追加時もSearchEngineでの実装のみでCLI・MCP両方に反映可能。

### ローカルLLM可用性検証（オプション実装予定）

#### Gemini vs ローカルLLMの可用性検証
**Problem**: Geminiバッチ処理は効率的だが、単一APIへの依存により選択肢が制限される。ローカルLLM（Ollama + Qwen3）の可用性を検証し、API依存のリスクを軽減する必要がある。

**Solution**: ハイブリッド検索システム完成後、可用性検証を実施。
- **検証対象**: ローカルLLMによるタグ付け処理の実用性評価
- **評価指標**: 実用最低ラインの品質達成、処理安定性、依存関係の独立性
- **実装タイミング**: 統合システム完了後のオプション作業
- **比較項目**: 
  - 処理時間（Gemini: 9時間 vs ローカル: 158時間）
  - 品質（実用最低ライン達成の有無）
  - 可用性（API依存なし、完全ローカル処理）
  - コスト（API料金 vs 電力・時間コスト）
- **期待結果**: API依存リスクを軽減するローカル処理選択肢の確立
- **現状**: Geminiバッチ処理が効率性で圧倒的優位、可用性検証が残り課題

### ユーザー入力補完システム（将来実装予定）

#### readline Tab補完機能
**Problem**: ユーザー名の入力時に正確な名前を覚えていない場合や、タイポが発生しやすい場合に、入力効率が低下している。既存のsafe_input.pyは汎用的な入力管理のため、特定用途の補完機能は分離して実装する必要がある。

**Solution**: safe_input.pyを拡張し、ユーザー名補完モードのON/OFF切り替え機能を実装予定。
- **補完モード管理**: ユーザー名補完の有効/無効を動的に切り替え
- **コンテキスト分離**: 通常入力と補完付き入力で異なる履歴管理
- **Tab補完機能**: 部分入力に対する前方一致ユーザー候補表示
- **統合設計**: 既存のHistoryManagerと連携し、補完機能使用時のみ有効化

#### 二段階ユーザー支援システム
**完了済み**: レーベンシュタイン距離による類似ユーザー検索（SearchEngine.suggest_similar_users）
**将来実装**: readline Tab補完との組み合わせによる包括的ユーザー支援
- **入力中**: Tab補完でリアルタイム候補表示
- **入力後**: 存在しないユーザーに対して類似ユーザー自動提案
- **使い分け**: 明確に知っている場合はTab補完、曖昧な場合は類似検索
