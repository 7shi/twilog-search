# Twilogベクトル検索システム設計計画

## なぜこの実装が存在するか

### 意味的検索の必要性
**Problem**: 単純な単語マッチングでは「git」「コミット」「リポジトリ」などの関連語や、表現の多様性に対応できない。「ソースコード管理」「変更履歴」「バージョン管理システム」などの同義語も検索対象にならない。

**Solution**: テキストをベクトル化し、コサイン類似度による意味的検索を実装。表現が異なっても概念的に近い投稿を発見できる。

### データ規模と実装方式の選択
**Problem**: 22万件の投稿データに対して、複雑なベクトルDBやクラウドサービスを導入すると過剰な複雑性とコストが発生する。

**Solution**: 分割ファイル格納方式を採用。
- 1000件ごとの分割処理で安全性確保
- safetensors形式による高速読み込み
- 中断・再開機能による長時間処理への対応
- インメモリ検索により数ミリ秒での全件検索

### データ前処理の重要性
**Problem**: 投稿データにはURL、メンション、ハッシュタグなどのノイズが含まれ、意味的ベクトル化の精度を低下させる。

**Solution**: ベクトル化前にURL除去、空白正規化などの前処理を実装。意味のあるテキストのみを対象とする。

### タグ検出システムの設計
**Problem**: 22万件の投稿から手動でタグを抽出するのは現実的でなく、クラウドAPIの利用はコストと処理時間の課題を伴う。
**Solution**: ローカルLLMによる逐次処理と、Gemini APIによるバッチ処理を組み合わせたハイブリッドな自動タグ付けシステムを構築。これにより、コストと処理時間のバランスを取りながら、大規模データに対応する。

### ハイブリッド検索システムの必要性
**Problem**: 単純なベクトル検索では、直接的な類似度のみで判断するため、関連性の高い投稿を見逃す可能性がある。例えば「バージョン管理」で検索した際に、内容は異なるが「git」タグを持つ関連投稿が検索対象外になる。

**Solution**: ベクトル検索とタグ検索を組み合わせたハイブリッド検索を実装。
- 検索語と投稿内容の直接的なベクトル類似度検索
- 検索語と類似するタグを特定し、そのタグを持つ投稿も対象化
- 二つの検索結果を統合してランキング
- 網羅性と精度の両立を実現

### 検索結果統合の重要性
**Problem**: 直接類似度検索とタグ経由検索で異なるスコア体系を持つため、単純な結果マージでは適切なランキングができない。

**Solution**: スコア統合戦略を採用。
- 直接類似度: 重み0.7（内容の関連性を重視）
- タグ経由類似度: 重み0.3（関連トピックの発見性を重視）
- 重複投稿の除去と最終ランキング算出
- 検索意図に応じた重み調整が可能

### WebSocketベースのアーキテクチャ分離と統合
**Problem**: ベクトル検索機能をアプリケーションに統合すると、重いライブラリ（torch、SentenceTransformers）の読み込みにより、開発時の頻繁な再起動で生産性が低下する。また、MCPサーバー（TypeScript）とSearchEngine（Python）でフィルタリング機能が二重実装され、保守性とコードの一貫性に問題があった。

**Solution**: SearchEngine中心の統合アーキテクチャを採用。
- **twilog_server.py**: 統合検索サーバー（デーモン）
- **search.py**: 軽量フロントエンド
- **MCPサーバー**: 単純なWebSocketラッパー
- 機能の一元化による保守性向上と開発効率改善

## 自動タグ付けパイプライン

### 1. 比較検討: 逐次処理 vs バッチ処理
- **逐次処理 (`add_tags.py`)**: ローカルLLM（Ollama）を利用。小規模なテストやGPU環境下での実行には向くが、全データ（22万件）の処理に約158時間かかると試算され、スケーラビリティに課題。
- **バッチ処理（Gemini API）**: クラウドの並列処理能力を最大限に活用。全データ処理を約9時間で完了（17.6倍高速化）し、コストと時間の両面で圧倒的に優位であることが確認された。

### 2. バッチ処理パイプライン
Geminiバッチ処理を効率化するため、以下のツール群を開発・整備した。
- **リクエスト生成 (`batch_generate.py`)**: APIの仕様に合わせ、1万件ずつのJSONLリクエストファイルを生成する。
- **ジョブ管理 (`gemini-batch`)**: バッチジョブの投入、進捗監視、結果取得を自動化する独立CLIツール。
- **結果分析 (`batch_usage.py`)**: 処理結果のトークン使用量やコストを計算・検証し、データ品質を担保する。
- **結果統合 (`batch_merge.py`)**: 全バッチの結果ファイルをマージし、重複除去と整合性チェックを経て、単一のタグ付きデータセットを生成する。

### 3. ハイブリッド検索用データ生成
- **要旨ベクトル化 (`batch_vectorize.py`)**: 統合されたタグ情報（reasoning, summary）を個別にベクトル化し、内容の類似度だけでなく、LLMが生成した要約や理由に基づいた多角的な検索を可能にする。

### ローカルLLM可用性検証（予定）
Geminiバッチ処理は効率的だが、単一APIへの依存により選択肢が制限される。ローカルLLM（Ollama + Qwen3）の可用性を検証し、API依存のリスクを軽減する必要がある。
- **検証対象**: ローカルLLMによるタグ付け処理の実用性評価
- **評価指標**: 実用最低ラインの品質達成、処理安定性、依存関係の独立性
- **実装タイミング**: 統合システム完了後のオプション作業
- **比較項目**: 
  - 処理時間（Gemini: 9時間 vs ローカル: 158時間）
  - 品質（実用最低ライン達成の有無）
  - 可用性（API依存なし、完全ローカル処理）
  - コスト（API料金 vs 電力・時間コスト）
- **期待結果**: API依存リスクを軽減するローカル処理選択肢の確立
- **現状**: Geminiバッチ処理が効率性で圧倒的優位、可用性検証が残り課題

## ファイル構成
```
twilog/
├── twilog.csv                # 元データ（CSVベースアクセス）
├── embeddings/               # ベクトル検索用（分割ファイル）
│   ├── 0000.safetensors      # 投稿ベクトル（1000件ずつ）
│   ├── 0001.safetensors      # ...
│   ├── meta.json             # メタデータ（CSVパス含む）
│   └── ...
├── tags/                     # タグ情報（分割ファイル、オプション）
│   ├── 0000.jsonl            # タグデータ（1000件ずつ）
│   └── ...
├── batch/                    # バッチAPIリクエスト（オプション）
│   ├── 001.jsonl             # Geminiバッチ用リクエスト（1万件ずつ）
│   └── ...
├── embed_server.py           # 基底クラス（BaseEmbedServer）
├── twilog_server.py          # 統合WebSocketサーバー（SearchEngine統合）
├── twilog_client.py          # テスト用クライアント
├── search.py                 # 軽量検索クライアント（フロントエンド化）
├── search_engine.py          # フィルタリング機能の中核
├── data_csv.py               # CSVベースデータアクセス層
├── add_tags.py               # CSVベースタグ付けスクリプト（完了）
├── batch_generate.py         # バッチAPIリクエスト生成（完了）
└── gemini-batch/             # 独立バッチツール（分離済み）
└── mcp/src/index.ts          # MCPラッパー（SQLite実装削除済み）
```

## 実装状況

### 完了済み: コア機能とアーキテクチャ
- **データ処理パイプライン**:
  - **タグ付け**: Geminiバッチ処理による22万件のタグ付け（`batch_generate.py` -> `gemini-batch` -> `batch_merge.py`）
  - **ベクトル化**: `batch_vectorize.py`によるハイブリッド検索用データの生成
- **統合アーキテクチャ**:
  - `twilog_server.py`を中心としたデーモン構成
  - `search_engine.py`へのフィルタリング機能集約
  - `search.py`の軽量フロントエンド化
  - `mcp/src/index.ts`のWebSocketラッパー化によるSQLite実装の完全排除
- **ハイブリッド検索システム**:
  - 6種類の検索モード（content, reasoning, summary, average, maximum, minimum）
  - `SearchEngine`レベルでの重み付けスコア統合
  - 詳細は[ハイブリッド検索実装レポート](docs/20250715-hybrid-search.md)を参照
- **性能と保守性**:
  - 22万件データに対して数ミリ秒での高速検索
  - SearchEngineへの機能一元化によるコード重複の排除

### 完了済み: UI/UXと操作性向上
- **クライアント機能**:
  - **コマンドシステム**: `@command`デコレーターによる宣言的なコマンド登録と管理
  - **メニューUI**: `settings_ui.py`による統一的なメニューと数値ショートカット
  - **検索結果表示**: ページネーション機能、URL右寄せ、タグの色分け表示
  - **表示モード**: `/view`コマンドによる詳細表示機能
  - 詳細は[メニューUI設計レポート](docs/20250716-menu.md)を参照
- **ユーザー入力支援**:
  - **Tab補完**: `safe_input.py`によるユーザー名のTab補完
  - **類似ユーザー推薦**: Levenshtein距離を用いたタイポ訂正支援
- **情報管理**:
  - **UserInfoクラス**: `user_info.py`によるユーザー統計情報の一元管理
  - **MCP連携**: 検索モード対応とYAML形式での統一出力

### 次期実装予定: タグベース検索機能

#### タグ集計・分析システム
**Problem**: 22万件のタグ付けデータが完了したが、タグ自体の集計・分析機能がないため、タグの使用頻度や関連性を把握できない。

**Solution**: タグデータの統計分析機能を実装。
- **タグ集計**: 使用頻度、出現パターン分析
- **関連性分析**: タグ間の共起関係、類似度計算
- **品質評価**: タグの一貫性と精度の検証

#### タグベース検索機能
**Problem**: 現在のハイブリッド検索では、タグ情報を検索結果に付加するのみで、タグ自体を検索対象とした機能がない。

**Solution**: タグを起点とした検索機能を実装。
- **タグ検索**: 特定タグに関連する投稿の検索
- **類似タグ発見**: 入力タグと類似するタグの発見
- **タグ経由投稿検索**: タグを介した関連投稿の検索
- **統合検索**: ベクトル検索とタグ検索の最終統合

#### 実装優先度
1. **高優先度**: タグ集計・分析機能の実装
2. **中優先度**: 基本的なタグ検索機能
3. **低優先度**: 統合検索システムへの組み込み
