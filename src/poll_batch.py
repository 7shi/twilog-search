#!/usr/bin/env python3
"""
job-info.jsonlã®å„ã‚¸ãƒ§ãƒ–ã‚’ãƒãƒ¼ãƒªãƒ³ã‚°ã—ã€å®Œäº†ã—ãŸã‚‰çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import json
import sys
import time
import argparse
import tempfile
from datetime import datetime
from pathlib import Path
from google import genai
from rich.live import Live
from rich.table import Table
from rich.console import Console
from rich.panel import Panel
from rich.text import Text

DEFAULT_JOB_INFO_FILE = "job-info.jsonl"
POLL_INTERVAL = 30  # 30ç§’é–“éš”ã§ãƒãƒ¼ãƒªãƒ³ã‚°

console = Console()

def create_job_status_display(jobs, last_update, countdown=None):
    """ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºã‚’ä½œæˆ"""
    table = Table(title="ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ç›£è¦–çŠ¶æ³")
    table.add_column("ãƒ•ã‚¡ã‚¤ãƒ«", style="cyan")
    table.add_column("çŠ¶æ…‹", style="magenta")
    table.add_column("ä½œæˆæ—¥æ™‚", style="dim")
    table.add_column("å®Œäº†æ—¥æ™‚", style="green")
    table.add_column("æ‰€è¦æ™‚é–“", style="yellow")
    
    completed_count = 0
    for job in jobs:
        input_file = job['input_file']
        
        if 'completed_at' in job:
            completed_count += 1
            final_state = job.get('final_state', '')
            if final_state == 'JOB_STATE_SUCCEEDED':
                status = "âœ“ æˆåŠŸ"
                status_style = "green"
            elif final_state == 'JOB_STATE_FAILED':
                status = "âœ— å¤±æ•—"
                status_style = "red"
            elif final_state == 'JOB_STATE_CANCELLED':
                status = "âŠ˜ ã‚­ãƒ£ãƒ³ã‚»ãƒ«"
                status_style = "orange1"
            else:
                # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚
                status = "âœ“ å®Œäº†"
                status_style = "green"
        else:
            status = "â³ å‡¦ç†ä¸­"
            status_style = "yellow"
        
        created_at = job.get('created_at', '')[:19].replace('T', ' ')
        completed_at = job.get('completed_at', '')[:19].replace('T', ' ') if 'completed_at' in job else ''
        
        # æ‰€è¦æ™‚é–“ã®è¡¨ç¤º
        duration_display = ""
        if 'duration_seconds' in job:
            duration_sec = job['duration_seconds']
            hours = duration_sec // 3600
            minutes = (duration_sec % 3600) // 60
            seconds = duration_sec % 60
            if hours > 0:
                duration_display = f"{hours}h {minutes}m {seconds}s"
            elif minutes > 0:
                duration_display = f"{minutes}m {seconds}s"
            else:
                duration_display = f"{seconds}s"
        
        table.add_row(
            input_file,
            Text(status, style=status_style),
            created_at,
            completed_at,
            duration_display
        )
    
    # ã‚µãƒãƒªãƒ¼æƒ…å ±
    total_jobs = len(jobs)
    pending_jobs = total_jobs - completed_count
    
    summary = Text()
    summary.append(f"ç·ã‚¸ãƒ§ãƒ–æ•°: {total_jobs} | ", style="bold")
    summary.append(f"å®Œäº†: {completed_count} | ", style="green bold")
    summary.append(f"æ®‹ã‚Š: {pending_jobs}", style="yellow bold")
    
    if countdown is not None:
        summary.append(f" | æ¬¡å›ãƒãƒ¼ãƒªãƒ³ã‚°: {countdown}ç§’", style="cyan")
    
    # ãƒ‘ãƒãƒ«ã«åŒ…ã‚€
    content = [
        Text(f"æœ€çµ‚æ›´æ–°: {last_update}", style="dim"),
        Text(""),
        summary,
        Text(""),
        table
    ]
    
    if pending_jobs == 0:
        content.append(Text(""))
        content.append(Text("ğŸ‰ ã™ã¹ã¦ã®ã‚¸ãƒ§ãƒ–ãŒå®Œäº†ã—ã¾ã—ãŸï¼", style="green bold"))
    
    from rich.columns import Columns
    from rich.align import Align
    
    return Panel(
        Align.center(Columns(content, equal=True, expand=True)),
        title="Gemini Batch Job Monitor",
        border_style="blue"
    )

def load_jobs_from_jsonl(job_info_file):
    """job-info.jsonlã‹ã‚‰ã‚¸ãƒ§ãƒ–æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€"""
    if not os.path.exists(job_info_file):
        print(f"ã‚¨ãƒ©ãƒ¼: ã‚¸ãƒ§ãƒ–æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {job_info_file}", file=sys.stderr)
        return []
    
    jobs = []
    try:
        with open(job_info_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                if line.strip():
                    try:
                        job_record = json.loads(line)
                        job_record['_line_num'] = line_num  # è¡Œç•ªå·ã‚’è¨˜éŒ²
                        jobs.append(job_record)
                    except json.JSONDecodeError as e:
                        print(f"è­¦å‘Š: {line_num}è¡Œç›®ã®JSONè§£æã«å¤±æ•—: {e}", file=sys.stderr)
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: ã‚¸ãƒ§ãƒ–æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}", file=sys.stderr)
        return []
    
    return jobs

def get_pending_jobs(jobs):
    """å®Œäº†ã—ã¦ã„ãªã„ã‚¸ãƒ§ãƒ–ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    return [job for job in jobs if 'completed_at' not in job]

def update_job_completion(job_info_file, jobs, job_index, completed_at_datetime, final_state):
    """æŒ‡å®šã•ã‚ŒãŸã‚¸ãƒ§ãƒ–ã«å®Œäº†æ™‚é–“ã€æ‰€è¦æ™‚é–“ã€æœ€çµ‚çŠ¶æ…‹ã‚’è¿½åŠ ã—ã¦JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°"""
    # è©²å½“ã‚¸ãƒ§ãƒ–ã«å®Œäº†æ™‚é–“ã¨æœ€çµ‚çŠ¶æ…‹ã‚’è¿½åŠ 
    jobs[job_index]['completed_at'] = completed_at_datetime.isoformat()
    jobs[job_index]['final_state'] = final_state
    
    # æ‰€è¦æ™‚é–“ã‚’è¨ˆç®—
    if 'created_at' in jobs[job_index]:
        try:
            created_time = datetime.fromisoformat(jobs[job_index]['created_at'])
            duration = completed_at_datetime - created_time
            jobs[job_index]['duration_seconds'] = int(duration.total_seconds())
        except Exception:
            # æ—¥æ™‚è§£æã«å¤±æ•—ã—ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            pass
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ–°ã—ã„å†…å®¹ã‚’æ›¸ãè¾¼ã¿
    temp_file = None
    try:
        with tempfile.NamedTemporaryFile(mode='w', encoding='utf-8', delete=False, 
                                       dir=os.path.dirname(job_info_file),
                                       prefix=f"{os.path.basename(job_info_file)}.tmp") as f:
            temp_file = f.name
            for job in jobs:
                # _line_numã¯å†…éƒ¨ç®¡ç†ç”¨ãªã®ã§é™¤å¤–
                job_data = {k: v for k, v in job.items() if k != '_line_num'}
                json.dump(job_data, f, ensure_ascii=False)
                f.write('\n')
        
        # å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¦ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªãƒãƒ¼ãƒ 
        os.remove(job_info_file)
        os.rename(temp_file, job_info_file)
        
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        if temp_file and os.path.exists(temp_file):
            try:
                os.remove(temp_file)
            except:
                pass
        raise e

def download_job_results(client, job, input_file_path):
    """ã‚¸ãƒ§ãƒ–ã®çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        # ã‚¸ãƒ§ãƒ–ã®æœ€æ–°çŠ¶æ…‹ã‚’å–å¾—
        batch_job = client.batches.get(name=job['job_name'])
        
        if batch_job.state.name != "JOB_STATE_SUCCEEDED":
            return False, f"ã‚¸ãƒ§ãƒ–ãŒæˆåŠŸã—ã¦ã„ã¾ã›ã‚“: {batch_job.state.name}"
        
        # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        result_file_name = batch_job.dest.file_name
        file_content_bytes = client.files.download(file=result_file_name)
        file_content = file_content_bytes.decode("utf-8")
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å…ˆãƒ‘ã‚¹ã‚’æ±ºå®šï¼ˆbatchãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®results/ï¼‰
        input_path = Path(input_file_path)
        results_dir = input_path.parent / "results"
        results_dir.mkdir(exist_ok=True)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã¯ input_path.name ã‚’ä½¿ç”¨
        output_file = results_dir / input_path.name
        
        # çµæœã‚’ä¿å­˜
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(file_content)
        
        return True, str(output_file)
        
    except Exception as e:
        return False, f"çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}"

def poll_jobs(job_info_file, client):
    """ã‚¸ãƒ§ãƒ–ã‚’ãƒãƒ¼ãƒªãƒ³ã‚°ã—ã¦å®Œäº†ã—ãŸã‚‚ã®ã‚’å‡¦ç†"""
    completed_states = {"JOB_STATE_SUCCEEDED", "JOB_STATE_FAILED", "JOB_STATE_CANCELLED"}
    
    with Live(console=console, refresh_per_second=1) as live:
        while True:
            # æœ€æ–°ã®ã‚¸ãƒ§ãƒ–æƒ…å ±ã‚’èª­ã¿è¾¼ã¿
            jobs = load_jobs_from_jsonl(job_info_file)
            if not jobs:
                live.update(Text("ã‚¨ãƒ©ãƒ¼: ã‚¸ãƒ§ãƒ–ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", style="red bold"))
                break
            
            # æœªå®Œäº†ã®ã‚¸ãƒ§ãƒ–ã‚’å–å¾—
            pending_jobs = get_pending_jobs(jobs)
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            if not pending_jobs:
                live.update(create_job_status_display(jobs, current_time))
                break
            
            # è¡¨ç¤ºã‚’æ›´æ–°
            live.update(create_job_status_display(jobs, current_time))
            
            # å„æœªå®Œäº†ã‚¸ãƒ§ãƒ–ã®çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯
            newly_completed = 0
            for i, job in enumerate(jobs):
                if 'completed_at' in job:
                    continue  # æ—¢ã«å®Œäº†æ¸ˆã¿
                
                try:
                    batch_job = client.batches.get(name=job['job_name'])
                    current_state = batch_job.state.name
                    
                    if current_state in completed_states:
                        # ã‚¸ãƒ§ãƒ–å®Œäº†ï¼ˆæˆåŠŸã€å¤±æ•—ã€ã‚­ãƒ£ãƒ³ã‚»ãƒ«å•ã‚ãšï¼‰
                        completed_at = datetime.now()
                        
                        if current_state == "JOB_STATE_SUCCEEDED":
                            # çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                            success, message = download_job_results(client, job, job['input_file'])
                            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœã¯å†…éƒ¨å‡¦ç†ã®ã¿
                        
                        # å®Œäº†æ™‚é–“ã¨æœ€çµ‚çŠ¶æ…‹ã‚’è¨˜éŒ²
                        update_job_completion(job_info_file, jobs, i, completed_at, current_state)
                        newly_completed += 1
                    
                except Exception as e:
                    # ã‚¨ãƒ©ãƒ¼ã¯å†…éƒ¨å‡¦ç†ã®ã¿ã€è¡¨ç¤ºã«ã¯å½±éŸ¿ã—ãªã„
                    pass
            
            if newly_completed > 0:
                # ã‚¸ãƒ§ãƒ–æƒ…å ±ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦æ¬¡ã®ãƒ«ãƒ¼ãƒ—ã¸
                continue
            
            # æœªå®Œäº†ã‚¸ãƒ§ãƒ–ãŒã¾ã ã‚ã‚‹å ´åˆã¯å¾…æ©Ÿ
            remaining = len(get_pending_jobs(load_jobs_from_jsonl(job_info_file)))
            if remaining > 0:
                for countdown in range(POLL_INTERVAL, -1, -1):
                    live.update(create_job_status_display(jobs, current_time, countdown))
                    time.sleep(1)

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="job-info.jsonlã®å„ã‚¸ãƒ§ãƒ–ã‚’ãƒãƒ¼ãƒªãƒ³ã‚°ã—ã€å®Œäº†ã—ãŸã‚‰çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
    )
    
    parser.add_argument(
        "--job-info",
        default=DEFAULT_JOB_INFO_FILE,
        help=f"ã‚¸ãƒ§ãƒ–æƒ…å ±JSONLãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_JOB_INFO_FILE}ï¼‰"
    )
    
    args = parser.parse_args()
    
    # Gemini APIã‚­ãƒ¼ã®ç¢ºèª
    if "GEMINI_API_KEY" not in os.environ:
        print("ã‚¨ãƒ©ãƒ¼: GEMINI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“", file=sys.stderr)
        sys.exit(1)
    
    # Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    try:
        client = genai.Client(
            api_key=os.environ["GEMINI_API_KEY"],
            http_options={"api_version": "v1alpha"}
        )
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—: {e}", file=sys.stderr)
        sys.exit(1)
    
    # ã‚¸ãƒ§ãƒ–ã‚’ãƒãƒ¼ãƒªãƒ³ã‚°
    try:
        poll_jobs(args.job_info, client)
        print("\nãƒãƒ¼ãƒªãƒ³ã‚°å®Œäº†")
    except KeyboardInterrupt:
        print("\nãƒãƒ¼ãƒªãƒ³ã‚°ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        print(f"\nã‚¨ãƒ©ãƒ¼: ãƒãƒ¼ãƒªãƒ³ã‚°ä¸­ã«äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    main()
