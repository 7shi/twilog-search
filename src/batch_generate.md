# バッチAPIリクエスト生成モジュール

## なぜこの実装が存在するか

### Geminiバッチ処理による大規模タグ付けの効率化
**Problem**: add_tags.pyのリアルタイム処理では22万件のタグ付けに158時間（6.6日間）を要し、処理中の中断リスクとリソース占有期間が問題となっていた。

**Solution**: Geminiバッチ処理APIに対応したJSONLリクエスト生成により、大量データを一括処理に移行。処理時間短縮とリソース効率化を実現した。

### add_tags.pyアーキテクチャの再利用による開発効率化
**Problem**: 全く新しいアーキテクチャでバッチ処理を実装すると、既存の設計思想やデータ処理ロジックを再開発する必要があり、開発コストが高い。

**Solution**: add_tags.pyのCSVデータアクセス、前処理ロジック、プロンプト設計を流用し、出力形式のみをJSONLに変更するアプローチを採用。

### 構造化プロンプトとスキーマの分離
**Problem**: add_tags.pyではPydanticスキーマから動的にプロンプトを生成していたが、バッチAPIではスキーマとプロンプトが独立して管理される。

**Solution**: 分析項目をプロンプト内にハードコーディングし、スキーマは型定義のみに簡素化。reasoningフィールドに「（日本語）」指定を追加して言語出力を安定化した。

### バッチAPI制限を考慮した適切なチャンクサイズの決定
**Problem**: 当初5万件ずつの分割（約70MB/ファイル）では、上限2GBに対して十分な余裕があると考えていたが、実際にはGeminiバッチAPIで429 (RESOURCE_EXHAUSTED)エラーにより処理が拒否された。ファイルサイズではなく、リクエスト件数に別の制限が存在していた。

**Solution**: 実測結果に基づき1万件チャンクに変更。22万件を23ファイル（約14MB/ファイル）に分割し、バッチAPI制限に適合しつつ処理可能なサイズに最適化した。

### 大量データの一括前処理による入力品質保証
**Problem**: バッチ処理では個別のデータ検証が困難で、不正なデータが混入すると全体の処理が失敗するリスクがある。

**Solution**: データ読み込み時にstrip_content処理を適用し、空データのフィルタリングとpost_idソートを実行。一貫性のある高品質な入力データセットを事前構築した。

### 段階的チャンク分割による処理可視性確保
**Problem**: 大量データの一括処理では進捗が不明で、処理状況の把握やデバッグが困難。

**Solution**: チャンクごとのファイル生成と進捗表示により、処理の可視性を確保。001.jsonl～023.jsonl等の連番ファイル命名で処理順序も明確化した。

### 既存ツールチェーンとの互換性維持
**Problem**: 新しいバッチ処理システムが既存のargparse構造やディレクトリ管理と異なると、運用時の学習コストが発生する。

**Solution**: add_tags.pyと同一のargparse構造とコマンドライン引数設計を採用。既存の運用知識をそのまま活用できる一貫したツールチェーンとした。