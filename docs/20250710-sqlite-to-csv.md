# SQLiteベースからCSVベースへの移行レポート

## 移行の背景

### 当初の判断（SQLiteベース採用）
**Problem**: Twilog.csv（227,011件）の大容量データを毎回全読み込みすると非効率的と判断
**Solution**: SQLiteデータベースを構築し、必要な部分のみを効率的にアクセスする分割処理アーキテクチャを採用

### 実装過程での発見
**Problem**: ベクトル検索の実装において、全件検索には結局全データをインメモリに保持する必要があると判明
**Solution**: 複雑なSQLiteデータベース構築手順を経由せず、CSVファイルから直接処理する単純化アーキテクチャへの転換

## 移行の判断理由

### 処理効率の観点
- **SQLiteベース**: 複数段階のデータ変換処理が必要
  - CSV → SQLite変換（conv.py）
  - テキスト前処理（preprocess_content.py）
  - ベクトル化（vectorize.py）
- **CSVベース**: 単一段階での直接処理
  - CSVから直接ベクトル化（vectorize.py）

### メモリ使用パターンの変化
- **当初想定**: 部分的データアクセスでメモリ効率化
- **実際の要件**: 検索時の全データインメモリ保持が必要
- **結論**: 全データ保持が前提なら、中間データベースの構築は不要

### 運用の簡単さ
- **SQLiteベース**: 8段階の複雑な処理手順
- **CSVベース**: 3段階の単純な処理手順
- **効果**: セットアップ時間の大幅短縮（数時間 → 約2時間）

## 技術的な違い

### データアクセス層の変更
- **data_sqlite.py**: SQLiteデータベース経由のアクセス
- **data_csv.py**: CSV直接アクセス（pandas使用）

### 処理アーキテクチャの変更
```
【SQLiteベース】
CSV → SQLite → 前処理 → ベクトル化 → 検索

【CSVベース】
CSV → ベクトル化 → 検索
```

### パフォーマンス比較
- **SQLiteベース**: 前処理でデータ品質向上、複雑な処理手順
- **CSVベース**: 生データ直接処理、単純な処理手順
- **検索性能**: 両方とも同等（全データインメモリ保持）

## 移行の影響

### 維持される機能
- ベクトル検索の精度と速度
- WebSocketベースの検索サーバー
- 対話的検索インターフェース
- MCP統合

### 簡略化された機能
- 細かいデータ正規化処理
- ユーザー・URL抽出
- 投稿分布分析
- タグ付け機能（将来的に対応予定）

### 新たな利点
- **セットアップの簡単さ**: 1コマンドでのベクトル化完了
- **保守性**: 処理手順の大幅簡略化
- **障害回復**: 中間ファイルの管理が不要

## 結論

### 設計哲学の変更
- **当初**: データベース中心の段階的処理
- **現在**: 全データインメモリ前提の直接処理

### 適用場面
- **CSVベース**: 検索機能のみが必要な場合（推奨）
- **SQLiteベース**: 詳細な分析・タグ付けが必要な場合

### 今後の方向性
CSVベースを主流とし、SQLiteベースは特別な分析要件がある場合のみ使用する方針を採用。

## 具体的な作業フロー比較

### 新アーキテクチャ（CSVベース）の作業フロー

#### 1. ベクトル化段階（必須）
```bash
uv run vectorize.py
```
- **入力**: twilog.csv（直接読み込み）
- **出力**: embeddings/ディレクトリ（226個の.safetensorsファイル）
- **処理内容**: Ruri3モデルによる1000件ずつの分割処理
- **処理時間**: 約1時間56分（GPU環境）
- **特徴**: 中断・再開機能対応、SQLiteデータベース不要

#### 2. 検索サーバー起動段階
```bash
uv run twilog_server.py start
```
- **入力**: embeddings/ディレクトリ
- **機能**: WebSocketベースの検索サーバー（デーモン）
- **処理**: Ruri3モデル初期化 + 埋め込みデータ読み込み
- **起動時間**: 約85秒（初回のみ）
- **特徴**: バックグラウンド実行、複数クライアント対応

#### 3. ベクトル検索段階
```bash
uv run search.py
```
- **入力**: twilog.csv + twilog_server.py（WebSocket通信）
- **機能**: 意味的検索による投稿発見（リモート検索）
- **表示**: ランク・類似度・ユーザー・日時・URL・内容
- **特徴**: 対話的検索インターフェース、ユーザーフィルタリング、表示件数調整
- **コマンド**: `/help`でヘルプ、`/user`でフィルタリング、`/top`で表示件数設定
- **起動時間**: 数秒（軽量クライアント）
- **アーキテクチャ**: data_csv.pyによるCSVベースデータアクセス

#### 4. MCP統合段階（オプション）
```bash
# Node.js MCPサーバー起動と対話的クライアント
uv run mcp_wrap.py node -- /path/to/twilog-mcp-server/dist/index.js --db /path/to/twilog.db
```
- **Node.js MCPサーバー**: TypeScript実装のMCPサーバー（twilog-mcp-server）
- **MCPラッパー**: 対話的JSON-RPCクライアント（mcp_wrap.py）
- **機能**: ツール一覧表示、YAML出力、ヘルプ機能（`/help <tool_name>`）
- **対応ツール**: 類似検索、テキスト検索、統計情報取得、ベクトル化

### 従来アーキテクチャ（SQLiteベース）の作業フロー

#### 1. データ確認段階
```bash
uv run read.py
```
- **入力**: twilog.csv
- **出力**: コンソール出力（データ統計情報）
- **目的**: CSVファイルの構造確認とデータ品質の初期評価

#### 2. データベース構築段階
```bash
uv run conv.py
```
- **入力**: twilog.csv
- **出力**: twilog.db（postsテーブル）
- **処理内容**: 22万件のデータを一括変換し、検索用インデックスを作成

#### 3. データ正規化段階（並列実行可能）
```bash
# 以下は任意の順序で実行可能
uv run extract_users.py
uv run extract_urls.py
uv run histogram.py
```

##### extract_users.py - ユーザー・投稿ID抽出
- **入力**: twilog.db（postsテーブル）
- **出力**: users.tsv + user_postsテーブル
- **処理結果**: 226,866件（重複除去後）

##### extract_urls.py - URL抽出
- **入力**: twilog.db（postsテーブル）
- **出力**: urls.tsv + post_urlsテーブル
- **処理内容**: 投稿内容からURLを抽出し1対多の関係で正規化

##### histogram.py - ユーザー投稿分布分析
- **入力**: twilog.db（user_postsテーブル）
- **出力**: histogram.png
- **分析結果**: ユーザー行動パターンの可視化

#### 4. テキスト前処理段階
```bash
uv run preprocess_content.py
```
- **入力**: twilog.db（postsテーブル）
- **出力**: processed_content.csv + processed_contentテーブル
- **処理内容**: URL・メンション除去、ハッシュタグ保持
- **処理結果**: 225,827件（空文字除去後）

#### 5. ベクトル化段階
```bash
uv run vectorize.py
```
- **入力**: twilog.db（processed_contentテーブル）
- **出力**: embeddings/ディレクトリ（226個の.safetensorsファイル）
- **処理内容**: Ruri3モデルによる1000件ずつの分割処理
- **処理時間**: 約1時間56分（GPU環境）
- **特徴**: 中断・再開機能対応

#### 6. 検索サーバー起動段階
```bash
uv run twilog_server.py start
```
- **入力**: embeddings/ディレクトリ
- **機能**: WebSocketベースの検索サーバー（デーモン）
- **処理**: Ruri3モデル初期化 + 埋め込みデータ読み込み
- **起動時間**: 約85秒（初回のみ）
- **特徴**: バックグラウンド実行、複数クライアント対応

#### 7. ベクトル検索段階
```bash
uv run search.py
```
- **入力**: twilog.csv + twilog_server.py（WebSocket通信）
- **機能**: 意味的検索による投稿発見（リモート検索）
- **表示**: ランク・類似度・ユーザー・日時・URL・内容
- **特徴**: 対話的検索インターフェース、ユーザーフィルタリング、表示件数調整
- **コマンド**: `/help`でヘルプ、`/user`でフィルタリング、`/top`で表示件数設定
- **起動時間**: 数秒（軽量クライアント）
- **アーキテクチャ**: data_csv.pyによるCSVベースデータアクセス
- **セットアップ**: データベース構築不要（CSVファイルのみ）

#### 8. MCP統合段階
```bash
# Node.js MCPサーバー起動と対話的クライアント
uv run mcp_wrap.py node -- /path/to/twilog-mcp-server/dist/index.js --db /path/to/twilog.db
```
- **Node.js MCPサーバー**: TypeScript実装のMCPサーバー（twilog-mcp-server）
- **MCPラッパー**: 対話的JSON-RPCクライアント（mcp_wrap.py）
- **機能**: ツール一覧表示、YAML出力、ヘルプ機能（`/help <tool_name>`）
- **対応ツール**: 類似検索、テキスト検索、統計情報取得、ベクトル化

#### 9. タグ付け段階（進行中）
```bash
uv run extract_tags.py
```
- **入力**: twilog.db（processed_contentテーブル）
- **出力**: tags/ディレクトリ（JSONLファイル群）
- **処理内容**: Ollama + Qwen3による構造化出力
- **処理時間（予測）**: 158.1時間, 6.6日間（GPU環境）
- **特徴**: 中断・再開機能対応

## 作業量の比較

### 新アーキテクチャ（CSVベース）
- **必須手順**: 3段階
- **総処理時間**: 約2時間（ベクトル化1時間56分 + サーバー起動85秒）
- **前提条件**: twilog.csvファイルのみ
- **中間ファイル**: embeddings/ディレクトリのみ

### 従来アーキテクチャ（SQLiteベース）
- **必須手順**: 8段階（データ確認 → DB構築 → 正規化3種 → 前処理 → ベクトル化 → 検索）
- **総処理時間**: 数時間（各段階の処理時間の合計）
- **前提条件**: twilog.csvファイル
- **中間ファイル**: twilog.db、users.tsv、urls.tsv、processed_content.csv、histogram.png
- **オプション**: タグ付け（+158時間）

## 実装の違い

### データアクセス層
- **新アーキテクチャ**: data_csv.py（pandasによるCSV直接読み込み）
- **従来アーキテクチャ**: data_sqlite.py（SQLiteデータベース経由）

### vectorize.pyの動作
- **新アーキテクチャ**: CSV → 前処理 → ベクトル化（一体化処理）
- **従来アーキテクチャ**: processed_contentテーブル → ベクトル化（分離処理）

### search.pyの動作
- **共通**: data_csv.pyを使用してCSVからメタデータを読み込み
- **検索処理**: 両方とも同じWebSocketベースの検索サーバーを使用